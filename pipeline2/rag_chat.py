from rag_retriever import search_kb
from local_llm import generate_answer

from categorizer import categorize_ticket

from sentiment_escalation import analyze_sentiment, detect_escalation

from routing_resolution import route_ticket, predict_resolution




def build_prompt(query, retrieved_chunks):
    context = "\n\n".join([r["text"] for r in retrieved_chunks])

    return f"""
Use the following support data to answer the question.

Context:
{context}

Question:
{query}

Write a professional support response and end with:

Best regards,
Subhasish Mahapatro
Customer Support Team
GIET University


Answer clearly and accurately.
"""

# OLD CODE 

'''def ask(query):
    chunks, scores = search_kb(query)

    prompt = build_prompt(query, chunks)
    answer = generate_answer(prompt)

    # Confidence
    confidence = max(0, 100 - scores[0] * 10)

    # Category
    category = categorize_ticket(chunks[0]["text"])

    # Sentiment
    sentiment = analyze_sentiment(chunks[0]["text"])

    # Escalation
    escalation = detect_escalation(sentiment, chunks[0]["text"])

    print(f"Category: {category}")
    print(f"Sentiment: {sentiment}")
    print(f"Escalation Status: {escalation}")

    return answer, confidence'''
    
def ask(query):
    chunks, scores = search_kb(query)

    prompt = build_prompt(query, chunks)
    answer = generate_answer(prompt)

    # Confidence
    confidence = max(0, 100 - scores[0] * 10)

    # Category
    category = categorize_ticket(chunks[0]["text"])

    # Sentiment
    sentiment = analyze_sentiment(chunks[0]["text"])

    # Escalation
    escalation = detect_escalation(sentiment, chunks[0]["text"])

    # Routing
    team = route_ticket(category, escalation)

    # Resolution Prediction
    resolution = predict_resolution(chunks[0]["text"])

    print(f"Category: {category}")
    print(f"Sentiment: {sentiment}")
    print(f"Escalation Status: {escalation}")
    print(f"Routed To: {team}")
    print(f"Predicted Resolution: {resolution}")

    return answer, confidence





if __name__ == "__main__":
    while True:
        q = input("\nAsk a question (type exit to quit): ")

        if q.lower() == "exit":
            break

        answer, confidence = ask(q)

        print("\n--- AI ANSWER ---")
        print(answer)
        print(f"\nConfidence: {confidence:.2f}%")

        '''print("\n--- SOURCES ---")
        for s in sources:
            print(s["metadata"])'''
            
            
'''
TO RUN THE FILE:

cd F:\1st_Rag_project\pipeline2
python rag_chat.py

üßæ General Understanding

Try these first:

‚Ä¢ What is this support ticket about?
‚Ä¢ Can you summarize the customer‚Äôs issue?
‚Ä¢ What problem is the customer facing?
‚Ä¢ What did the customer request in this ticket?

üõ†Ô∏è Resolution & Guidance

Customer is very frustrated and wants immediate fix

‚Ä¢ How should the support team respond to this ticket?
‚Ä¢ What steps can be taken to solve this issue?
‚Ä¢ What is the best solution for the customer‚Äôs problem?
‚Ä¢ How can we assist the customer effectively?

üìß Auto-Response Style (professional)

‚Ä¢ Write a professional reply for this ticket
‚Ä¢ Draft a support response to the customer
‚Ä¢ Provide a polite resolution message
‚Ä¢ How should we reply to this customer inquiry?

üìä When you add more tickets later (real power)

These will work even better as KB grows:

‚Ä¢ Have we seen similar issues before?
‚Ä¢ How were similar tickets resolved?
‚Ä¢ What is the common solution for this type of problem?
‚Ä¢ What patterns exist in customer issues?

üö® Advanced (future when you scale)

‚Ä¢ Which tickets need urgent attention?
‚Ä¢ Are customers satisfied with resolutions?
‚Ä¢ What are the most common problems reported?

'''
